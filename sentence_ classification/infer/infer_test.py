#!/usr/bin/env python
# -*- coding: utf-8 -*-

print("ìš•ì„¤ íƒì§€ ëª¨ë¸ ì¸í¼ëŸ°ìŠ¤ ì‹œì‘")

import torch
from transformers import BertTokenizer, BertConfig, BertForSequenceClassification

# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì„¤ì •
MODEL_DIR = "/home/pkw85428/model/ckpt/checkpoint-72"
PRETRAINED_MODEL_NAME = "beomi/kcbert-base"
MAX_SEQ_LENGTH = 64

tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME, do_lower_case=False)

config = BertConfig.from_pretrained(MODEL_DIR)
model = BertForSequenceClassification.from_pretrained(MODEL_DIR, config=config)
model.eval()

# ì˜ˆì¸¡ í•¨ìˆ˜
def inference_fn(premise: str, hypothesis: str):
    inputs = tokenizer(
        [(premise, hypothesis)],
        return_tensors="pt",
        max_length=MAX_SEQ_LENGTH,
        padding="max_length",
        truncation=True,
    )

    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.softmax(outputs.logits, dim=1)

        pred_idx = torch.argmax(probs, dim=1).item()
        label_map = {
            0: " ìš•ì„¤",
            1: " ì •ìƒ",
            2: " ì¤‘ë¦½"
        }
        pred = label_map.get(pred_idx, "ì•Œ ìˆ˜ ì—†ìŒ")

        return {
            "premise": premise,
            "hypothesis": hypothesis,
            "íŒë‹¨": pred,
            "í™•ë¥ ": {
                "ìš•ì„¤": round(probs[0][0].item(), 4),
                "ì •ìƒ": round(probs[0][1].item(), 4),
                "ì¤‘ë¦½": round(probs[0][2].item(), 4),
            }
        }

# CLI ì…ë ¥ ë£¨í”„
print("\nğŸ’¬ ì˜ˆì‹œ: 'ì´ ë¬¸ì¥ì€ ìš•ì„¤ì´ë‹¤' + í…ŒìŠ¤íŠ¸ ë¬¸ì¥")
while True:
    try:
        hypo = input("\n[ì…ë ¥] íŒë³„í•  ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: Ctrl+C): ")
        result = inference_fn("ì´ ë¬¸ì¥ì€ ìš•ì„¤ì´ë‹¤", hypo)

        print("\n[íŒë³„ ê²°ê³¼]")
        print(f"ë¬¸ì¥: {result['hypothesis']}")
        print(f"íŒë‹¨: {result['íŒë‹¨']}")
        print("í™•ë¥ :")
        for k, v in result["í™•ë¥ "].items():
            print(f"  - {k}: {v}")
    except KeyboardInterrupt:
        print("\n ì¢…ë£Œí•©ë‹ˆë‹¤.")
        break
